# -*- coding: utf-8 -*-
"""pictures2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uZx68xaMQ5mhnodTq4By2XNtrpSVFkOh
"""

# Download and import libraries only the first time
!pip install torch torchvision matplotlib numpy scikit-image pillow==4.1.1

# Commented out IPython magic to ensure Python compatibility.
# For plotting Everytime
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
# For conversion
from skimage.color import lab2rgb, rgb2lab, rgb2gray
from skimage import io
# For everything
import torch
import torch.nn as nn
import torch.nn.functional as F
# For our model
import torchvision.models as models
from torchvision import datasets, transforms
# For utilities
import os, os.path, shutil
import time, datetime
from datetime import datetime

#Everytime
from google.colab import drive
drive.mount('/content/drive')
#os.getcwd()

os.chdir('drive/My Drive')

#Download places365 images dataset from MIT Only the first time
#!wget http://data.csail.mit.edu/places/places365/test_256.tar
#!wget http://data.csail.mit.edu/places/places365/val_256.tar
!wget http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar

#Untar the file Only the first time
#!tar -xf test_256.tar
#!tar -xf val_256.tar
!tar -xf images.tar

#Only the first time
os.rename('Images', 'test_256')
for root, dir, files in os.walk(top='test_256'):
    for file in files:
        if file.endswith(".jpg"):  #match files that match this extension
            shutil.move(os.path.join(root, file), 'test_256')
os.chdir('test_256')
!rename 's/n0*_/''/' *.jpg
os.chdir('..')

#os.listdir('.')

#os.listdir('test_256/')

#os.chdir('test_256')

#!rename 's/n0*_/''/' *.jpg

rename -n -v  's/^(.{5})//' *.jpg

os.getcwd()

dirListing = os.listdir('test_256')
print(len(dirListing))

#shutil.rmtree('train')
#shutil.rmtree('validate')
#shutil.rmtree('state')
#shutil.rmtree('checkpoints')
#shutil.rmtree('test_256')

# Move data into training and validation directories
#Only The first Time
os.makedirs('train/images/', exist_ok=True) # 10000 images
os.makedirs('validate/images/', exist_ok=True)   #  1,000 images

for i, file in enumerate(os.listdir('test_256')):
  if i < 1000: # first 1k will be validation
    shutil.move('test_256/'+file, 'validate/images/'+file)
  elif i < 11000 and i>=1000: # the next 10K will be train
    shutil.move('test_256/'+file, 'train/images/'+file)
  else: break

dirListing = os.listdir('validate/images')

print(len(dirListing))
dirListing = os.listdir('train/images')

print(len(dirListing))

class ColorizationNet(nn.Module):
  def __init__(self, input_size=128):
    super(ColorizationNet, self).__init__()
    MIDLEVEL_FEATURE_SIZE = 128

    ## First half: ResNet
    resnet = models.resnet18(num_classes=365) 
    # Change first conv layer to accept single-channel (grayscale) input
    resnet.conv1.weight = nn.Parameter(resnet.conv1.weight.sum(dim=1).unsqueeze(1)) 
    # Extract midlevel features from ResNet-gray
    self.midlevel_resnet = nn.Sequential(*list(resnet.children())[0:6])

    ## Second half: Upsampling
    self.upsample = nn.Sequential(     
      nn.Conv2d(MIDLEVEL_FEATURE_SIZE, 128, kernel_size=3, stride=1, padding=1),
      nn.BatchNorm2d(128),
      nn.ReLU(),
      nn.Upsample(scale_factor=2),
      nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),
      nn.BatchNorm2d(64),
      nn.ReLU(),
      nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),
      nn.BatchNorm2d(64),
      nn.ReLU(),
      nn.Upsample(scale_factor=2),
      nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),
      nn.BatchNorm2d(32),
      nn.ReLU(),
      nn.Conv2d(32, 2, kernel_size=3, stride=1, padding=1),
      nn.Upsample(scale_factor=2)
    )

  def forward(self, input):

    # Pass input through ResNet-gray to extract features
    midlevel_features = self.midlevel_resnet(input)

    # Upsample to get colors
    output = self.upsample(midlevel_features)
    return output

#Model Creation
model = ColorizationNet()
#Loss Function
criterion = nn.MSELoss()
#Adam Optimizer
optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=0.0)

class GrayscaleImageFolder(datasets.ImageFolder):
  '''Custom images folder, which converts images to grayscale before loading'''
  def __getitem__(self, index):
    path, target = self.imgs[index]
    img = self.loader(path)
    if self.transform is not None:
      img_original = self.transform(img)
      img_original = np.asarray(img_original)
      img_lab = rgb2lab(img_original)
      img_lab = (img_lab + 128) / 255
      img_ab = img_lab[:, :, 1:3]
      img_ab = torch.from_numpy(img_ab.transpose((2, 0, 1))).float()
      img_original = rgb2gray(img_original)
      img_original = torch.from_numpy(img_original).unsqueeze(0).float()
    if self.target_transform is not None:
      target = self.target_transform(target)
    return img_original, img_ab, target

# Training
train_transforms = transforms.Compose([transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip()])
train_imagefolder = GrayscaleImageFolder('train', train_transforms)
train_loader = torch.utils.data.DataLoader(train_imagefolder, batch_size=64, shuffle=True)

# Validation 
val_transforms = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224)])
val_imagefolder = GrayscaleImageFolder('validate' , val_transforms)
val_loader = torch.utils.data.DataLoader(val_imagefolder, batch_size=64, shuffle=False)

class AverageMeter(object):
  '''A handy class from the PyTorch ImageNet tutorial''' 
  def __init__(self):
    self.reset()
  def reset(self):
    self.val, self.avg, self.sum, self.count = 0, 0, 0, 0
  def update(self, val, n=1):
    self.val = val
    self.sum += val * n
    self.count += n
    self.avg = self.sum / self.count

def to_rgb(epoch, grayscale_input, ab_input, save_path=None, save_name=None):
  '''Show/save rgb image from grayscale and ab channels
     Input save_path in the form {'grayscale': '/path/', 'colorized': '/path/'}'''
  plt.clf() # clear matplotlib 
  color_image = torch.cat((grayscale_input, ab_input), 0).numpy() # combine channels
  color_image = color_image.transpose((1, 2, 0))  # rescale for matplotlib
  color_image[:, :, 0:1] = color_image[:, :, 0:1] * 100
  color_image[:, :, 1:3] = color_image[:, :, 1:3] * 255 - 128   
  color_image = lab2rgb(color_image.astype(np.float64))
  grayscale_input = grayscale_input.squeeze().numpy()
  if save_path is not None and save_name is not None:
    plt.imsave(arr=color_image, fname='{}{}'.format(save_path['colorized'], save_name))
    if epoch == 0 : 
      plt.imsave(arr=grayscale_input, fname='{}{}'.format(save_path['grayscale'], save_name), cmap='gray')
    #plt.imsave(arr=color_image, fname='{}{}'.format(save_path['colorized'], save_name))

#def validate(val_loader, model, criterion, save_images, epoch):
def validate(val_loader, model, criterion, epoch):
  model.eval()

  # Prepare value counters and timers
  #batch_time, data_time, losses = AverageMeter(), AverageMeter(), AverageMeter()
  losses = AverageMeter()

  end = time.time()
  #already_saved_images = False
  saved = False
  for i, (input_gray, input_ab, target) in enumerate(val_loader):

    input_gray, input_ab, target = input_gray.cuda(), input_ab.cuda(), target.cuda()

    # Run model and record loss
    output_ab = model(input_gray) # throw away class predictions
    loss = criterion(output_ab, input_ab)
    losses.update(loss.item(), input_gray.size(0))

    # Save images to file
    #if save_images and not already_saved_images:
    if not saved:
      #already_saved_images = True
      saved = True
      #for j in range(min(len(output_ab)), 1000,20): # save 50 images  
      for j in range(min(len(output_ab), 50)): # save 50 images 
        save_path = {'grayscale': 'outputs/gray/', 'colorized': 'outputs/color/'}
        save_name = 'img-{}-epoch-{}.jpg'.format(i * val_loader.batch_size + j, epoch)
        to_rgb(epoch, input_gray[j].cpu(), ab_input=output_ab[j].detach().cpu(), save_path=save_path, save_name=save_name)
          
    
  print('Finished validation.')
  return losses.avg

def train(train_loader, model, criterion, optimizer, epoch):
  print('Starting training epoch {}'.format(epoch))
  model.train()
  
  # Prepare value counters and timers
  #batch_time, data_time, losses = AverageMeter(), AverageMeter(), AverageMeter()
  losses = AverageMeter()

  #end = time.time()
  for i, (input_gray, input_ab, target) in enumerate(train_loader):
    
    input_gray, input_ab, target = input_gray.cuda(), input_ab.cuda(), target.cuda()
    
    # Run forward pass
    output_ab = model(input_gray) 
    loss = criterion(output_ab, input_ab) 
    losses.update(loss.item(), input_gray.size(0))

    # Compute gradient and optimize
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

  now = datetime.now()
  print('Finished training epoch {} at {}'.format(epoch,now))

os.getcwd()

#Uncomment and run if you want to continue from a previous checkpoint and select the name
#from the outuput
os.listdir('checkpoints')

#Run ***ONLY*** When to Continue for a previously created Checkpoint
#***REPLACE CHECKPOINT NAME***
os.chdir('checkpoints')
#Replace model-epoch-74-losses-0.002.pth with the desired check point
checkpoint = torch.load('model-epoch-120-losses-0.00195.pth', map_location=lambda storage, loc: storage)


#Change value if restoring from checkpoint out of order
#epoch= 120
model.load_state_dict(checkpoint)
os.chdir('..')

#epoch=132

#********************************
#Uncomment and change the value according to the chosen checkpoint e.g. model-epoch-74-losses-0.002.pth --> best_losses=0.002
#********************************
best_losses = 0.00195

#print (epoch);
try: 
  epoch
except NameError:
  print("Model NOT trained yet")
else: 
  print ("Previously Reached Epoch:",epoch-1)

# Output folders and set parameters
os.makedirs('outputs/color', exist_ok=True)
os.makedirs('outputs/gray', exist_ok=True)
os.makedirs('checkpoints', exist_ok=True)
#best_losses = 0.002
epochs = 100
#Initialize Epoch counter and best lossed flag
#in case we are just starting training
#and not resuming from a checkpoint
try: 
  epoch
except NameError:
  best_losses = 1e10 
  epoch = 0
 
now = datetime.now()
print("Training Start Timestamp:", now)
# Train model
for epoch in range(epoch, epoch+epochs):
#for epoch in range(epochs):
  # Train for one epoch, then validate
  train(train_loader, model.cuda(), criterion.cuda(), optimizer, epoch)
  with torch.no_grad():
    #losses = validate(val_loader, model.cuda(), criterion.cuda(), save_images, epoch)
    losses = validate(val_loader, model.cuda(), criterion.cuda(), epoch)
  # Save checkpoint and replace old best model if current model is better
  if losses < best_losses:
    best_losses = losses
    print ("Lower Average Losses Found")
    torch.save(model.cuda().state_dict(), 'checkpoints/model-epoch-{}-losses-{:.5f}.pth'.format(epoch+1,losses))
    
now = datetime.now()
print("Training Stop Timestamp:", now)

# Show images 
import matplotlib.image as mpimg
#fix paths
image_pairs = [('outputs/color/img-22-epoch-120jpg', 'outputs/gray/img-22-epoch-0.jpg'),
               ('outputs/color/img-35-epoch-120jpg', 'outputs/gray/img-35-epoch-0.jpg')]

for c, g in image_pairs:
  color = mpimg.imread(c)
  gray  = mpimg.imread(g)
  f, axarr = plt.subplots(1, 2)
  f.set_size_inches(15, 15)
  axarr[0].imshow(gray, cmap='gray')
  axarr[1].imshow(color)
  axarr[0].axis('off'), axarr[1].axis('off')
  plt.show()

#Create a downloadable file in the mounted Google Drive with the a sample of colored photos from each epoch trained
!tar -zcf colored_images.tar.gz ./outputs/color/*epoch-167.jpg

#Create a downloadable file in the mounted Google Drive with every epoch check point
!tar -zcf checkpoints.tar ./checkpoints/

#Sources
#https://github.com/pytorch/examples/blob/master/imagenet/main.py
#https://pytorch.org/tutorials/  
#http://iizuka.cs.tsukuba.ac.jp/projects/colorization/en/
#https://blog.floydhub.com/colorizing-b-w-photos-with-neural-networks/